"""
Generate Rust const arrays from trained model weights.

Reads the JSON weight files exported by training/train.py and generates
a Rust source file with Q16.16 fixed-point i32 const arrays suitable for
embedding in the Arcis circuit.

Usage:
  python3 scripts/generate_circuit_weights.py
"""

import json
import os

SCALE = 65536  # Q16.16: 2^16
MODELS_DIR = os.path.join(os.path.dirname(__file__), "..", "models")
OUTPUT_PATH = os.path.join(os.path.dirname(__file__), "..", "encrypted-ixs", "src", "weights.rs")


def from_f64(val: float) -> int:
    """Convert f64 to Q16.16 i32 — must match arcinfer_core::fixed_point::from_f64."""
    return int(round(val * SCALE))


def format_1d_array(values: list[int], type_str: str, name: str, width: int) -> str:
    """Format a 1D array as a Rust const."""
    items = ", ".join(str(v) for v in values)
    return f"pub const {name}: [{type_str}; {len(values)}] = [{items}];"


def format_2d_array(rows: list[list[int]], type_str: str, name: str, outer: int, inner: int) -> str:
    """Format a 2D array as a Rust const."""
    lines = [f"pub const {name}: [[{type_str}; {inner}]; {outer}] = ["]
    for row in rows:
        items = ", ".join(str(v) for v in row)
        lines.append(f"    [{items}],")
    lines.append("];")
    return "\n".join(lines)


def main():
    # Load classifier weights
    weights_path = os.path.join(MODELS_DIR, "classifier_weights.json")
    with open(weights_path) as f:
        raw = json.load(f)

    # Quantize each layer
    l1_w = [[from_f64(v) for v in row] for row in raw["net.0.weight"]]  # 16x16
    l1_b = [from_f64(v) for v in raw["net.0.bias"]]                     # 16
    l2_w = [[from_f64(v) for v in row] for row in raw["net.2.weight"]]  # 8x16
    l2_b = [from_f64(v) for v in raw["net.2.bias"]]                     # 8
    l3_w = [[from_f64(v) for v in row] for row in raw["net.4.weight"]]  # 2x8
    l3_b = [from_f64(v) for v in raw["net.4.bias"]]                     # 2

    # Verify dimensions (16→16→8→2 architecture)
    assert len(l1_w) == 16 and len(l1_w[0]) == 16, f"Layer 1 weights: expected 16x16, got {len(l1_w)}x{len(l1_w[0])}"
    assert len(l1_b) == 16, f"Layer 1 bias: expected 16, got {len(l1_b)}"
    assert len(l2_w) == 8 and len(l2_w[0]) == 16, f"Layer 2 weights: expected 8x16, got {len(l2_w)}x{len(l2_w[0])}"
    assert len(l2_b) == 8, f"Layer 2 bias: expected 8, got {len(l2_b)}"
    assert len(l3_w) == 2 and len(l3_w[0]) == 8, f"Layer 3 weights: expected 2x8, got {len(l3_w)}x{len(l3_w[0])}"
    assert len(l3_b) == 2, f"Layer 3 bias: expected 2, got {len(l3_b)}"

    # Verify all values fit in i32
    all_values = []
    for row in l1_w + l2_w + l3_w:
        all_values.extend(row)
    all_values.extend(l1_b + l2_b + l3_b)
    max_abs = max(abs(v) for v in all_values)
    assert max_abs < 2**31, f"Value overflow: max |value| = {max_abs}, exceeds i32 range"

    # Count total parameters
    total = sum(len(row) for row in l1_w) + len(l1_b) + \
            sum(len(row) for row in l2_w) + len(l2_b) + \
            sum(len(row) for row in l3_w) + len(l3_b)
    expected_total = 16*16 + 16 + 8*16 + 8 + 2*8 + 2  # 426
    assert total == expected_total, f"Expected {expected_total} parameters, got {total}"

    # Generate Rust source
    lines = [
        "/// Auto-generated Q16.16 fixed-point weights for the Arcis circuit.",
        "///",
        "/// Generated by: python3 scripts/generate_circuit_weights.py",
        f"/// Total parameters: {total}",
        f"/// Max |value|: {max_abs} (Q16.16 scale = {SCALE})",
        "///",
        "/// These constants are PUBLIC — they are baked into the MPC circuit.",
        "/// Only the input features are encrypted (secret-shared).",
        "",
        "/// Q16.16 scale factor: multiply by this to convert f64 → i32.",
        f"pub const SCALE: i64 = {SCALE};",
        "",
        "// =========================================================================",
        "// Layer 1: 16 → 16 (256 weights + 16 biases)",
        "// =========================================================================",
        "",
        format_2d_array(l1_w, "i32", "L1_WEIGHTS", 16, 16),
        "",
        format_1d_array(l1_b, "i32", "L1_BIASES", 16),
        "",
        "// =========================================================================",
        "// Layer 2: 16 → 8 (128 weights + 8 biases)",
        "// =========================================================================",
        "",
        format_2d_array(l2_w, "i32", "L2_WEIGHTS", 8, 16),
        "",
        format_1d_array(l2_b, "i32", "L2_BIASES", 8),
        "",
        "// =========================================================================",
        "// Layer 3: 8 → 2 (16 weights + 2 biases)",
        "// =========================================================================",
        "",
        format_2d_array(l3_w, "i32", "L3_WEIGHTS", 2, 8),
        "",
        format_1d_array(l3_b, "i32", "L3_BIASES", 2),
    ]

    # Ensure output directory exists
    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)

    with open(OUTPUT_PATH, "w") as f:
        f.write("\n".join(lines) + "\n")

    print(f"Generated {OUTPUT_PATH}")
    print(f"  {total} parameters as Q16.16 i32 constants")
    print(f"  Max |value|: {max_abs}")
    print(f"  Layer 1: {len(l1_w)}x{len(l1_w[0])} weights + {len(l1_b)} biases")
    print(f"  Layer 2: {len(l2_w)}x{len(l2_w[0])} weights + {len(l2_b)} biases")
    print(f"  Layer 3: {len(l3_w)}x{len(l3_w[0])} weights + {len(l3_b)} biases")


if __name__ == "__main__":
    main()
